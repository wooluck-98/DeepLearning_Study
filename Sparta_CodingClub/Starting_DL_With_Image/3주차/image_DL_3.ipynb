{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "facenet = cv2.dnn.readNet('models/deploy.prototxt', 'models/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "model = load_model('models/mask_detector.model')\n",
    "\n",
    "cap = cv2.VideoCapture('videos/04.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    if ret == False:    \n",
    "        break\n",
    "\n",
    "    h, w, c = img.shape\n",
    "    # 이미지 전처리하기\n",
    "    blob = cv2.dnn.blobFromImage(img, size=(300, 300), mean=(104., 177., 123.))\n",
    "\n",
    "    # 얼굴 영역 탐지 모델로 추론하기\n",
    "    facenet.setInput(blob)\n",
    "    dets = facenet.forward()\n",
    "\n",
    "    # 각 얼굴에 대해서 반복문 돌기\n",
    "    for i in range(dets.shape[2]):\n",
    "        confidence = dets[0, 0, i, 2]\n",
    "\n",
    "        if confidence < 0.5:\n",
    "            continue\n",
    "\n",
    "        # 사각형 꼭지점 찾기\n",
    "        x1 = int(dets[0, 0, i, 3] * w)\n",
    "        y1 = int(dets[0, 0, i, 4] * h)\n",
    "        x2 = int(dets[0, 0, i, 5] * w)\n",
    "        y2 = int(dets[0, 0, i, 6] * h)\n",
    "\n",
    "        face = img[y1:y2, x1:x2]\n",
    "\n",
    "        face_input = cv2.resize(face, dsize=(224, 224))\n",
    "        face_input = cv2.cvtColor(face_input, cv2.COLOR_BGR2RGB)\n",
    "        face_input = preprocess_input(face_input)\n",
    "        face_input = np.expand_dims(face_input, axis=0)\n",
    "\n",
    "        mask, nomask = model.predict(face_input).squeeze()\n",
    "\n",
    "        if mask > nomask:\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            color = (0, 0, 255)\n",
    "            \n",
    "        # 사각형 그리기\n",
    "        cv2.rectangle(img, pt1=(x1, y1), pt2=(x2, y2), thickness=2, color=color)\n",
    "\n",
    "    cv2.imshow('result', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "age_list = ['(0, 2)','(4, 6)','(8, 12)','(15, 20)','(25, 32)','(38, 43)','(48, 53)','(60, 100)']\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "facenet = cv2.dnn.readNet('models/deploy.prototxt', 'models/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "age_net = cv2.dnn.readNetFromCaffe('models/deploy_age.prototxt', 'models/age_net.caffemodel')\n",
    "gender_net = cv2.dnn.readNetFromCaffe('models/deploy_gender.prototxt', 'models/gender_net.caffemodel')\n",
    "\n",
    "img = cv2.imread('imgs/02.jpg')\n",
    "\n",
    "h, w, c = img.shape\n",
    "\n",
    "# 이미지 전처리하기\n",
    "blob = cv2.dnn.blobFromImage(img, size=(300, 300), mean=(104., 177., 123.))\n",
    "\n",
    "# 얼굴 영역 탐지 모델로 추론하기\n",
    "facenet.setInput(blob)\n",
    "dets = facenet.forward()\n",
    "\n",
    "# 각 얼굴에 대해서 반복문 돌기\n",
    "for i in range(dets.shape[2]):\n",
    "    confidence = dets[0, 0, i, 2]\n",
    "\n",
    "    if confidence < 0.5:\n",
    "        continue\n",
    "\n",
    "    # 사각형 꼭지점 찾기\n",
    "    x1 = int(dets[0, 0, i, 3] * w)\n",
    "    y1 = int(dets[0, 0, i, 4] * h)\n",
    "    x2 = int(dets[0, 0, i, 5] * w)\n",
    "    y2 = int(dets[0, 0, i, 6] * h)\n",
    "\n",
    "    face = img[y1:y2, x1:x2]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(face, size=(227, 227), mean=(78.4263377603, 87.7689143744, 114.895847746))\n",
    "\n",
    "    gender_net.setInput(blob)\n",
    "    gender_index = gender_net.forward().squeeze().argmax()\n",
    "    gender = gender_list[gender_index]\n",
    "\n",
    "    age_net.setInput(blob)\n",
    "    age_index = age_net.forward().squeeze().argmax()\n",
    "    age = age_list[age_index]\n",
    "\n",
    "    cv2.rectangle(img, pt1=(x1, y1), pt2=(x2, y2), color=(255, 0, 0), thickness=2)\n",
    "    cv2.putText(img, '%s, %s' % (gender, age), org=(x1, y1), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,255,0), thickness=2)\n",
    "\n",
    "cv2.imshow('result', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
